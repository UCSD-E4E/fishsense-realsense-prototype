{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555f422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import stumpy\n",
    "import os\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a773b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to separate audio from the video. The audio will later be used for synchronization\n",
    "\n",
    "# Edit the directories for the mp4 files as necessary.\n",
    "\n",
    "left_dir = r\"left.mp4\"\n",
    "right_dir = r\"right.mp4\"\n",
    "\n",
    "\n",
    "# Extract audios from the video files. Use .wav because it is lossless.\n",
    "\n",
    "left = mp.VideoFileClip(left_dir)\n",
    "left.audio.write_audiofile(r\"left.wav\")\n",
    "\n",
    "right= mp.VideoFileClip(right_dir)\n",
    "\n",
    "right.audio.write_audiofile(r\"right.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fe146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin uploading audio from file into a numpy array\n",
    "\n",
    "left_wav = wave.open(\"left.wav\", \"rb\")\n",
    "right_wav = wave.open(\"right.wav\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue uploading audio from file into a numpy array\n",
    "\n",
    "left_freq = left_wav.getframerate()\n",
    "right_freq = right_wav.getframerate()\n",
    "\n",
    "left_samples = left_wav.getnframes()\n",
    "right_samples = right_wav.getnframes()\n",
    "\n",
    "left_signal = left_wav.readframes(left_samples)\n",
    "right_signal = right_wav.readframes(right_samples)\n",
    "\n",
    "left_audio = left_samples/left_freq\n",
    "right_audio = right_samples/right_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into an int16 file. Otherwise, the following functions wont' work (couldn't figure out why)\n",
    "\n",
    "left_signal_array = np.frombuffer(left_signal, dtype=np.int16)\n",
    "right_signal_array = np.frombuffer(right_signal, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7151b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These create the \"x\" values, or the times. Each time corresponds to a different signal value. \n",
    "\n",
    "times_left = np.linspace(0, left_samples/left_freq, num=left_samples)\n",
    "times_right = np.linspace(0, right_samples/right_freq, num=right_samples)\n",
    "\n",
    "# Use right channel for left camera and left channel for right camera\n",
    "left_channel = left_signal_array[1::2]\n",
    "right_channel = right_signal_array[0::2]\n",
    "\n",
    "\n",
    "# fft_left = np.fft.fft(left_channel)\n",
    "# fft_right = np.fft.fft(right_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the signal values of the left camera\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times_left, left_channel)\n",
    "plt.title('Left Camera')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(0, left_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94105306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the signal values of the right camera\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times_right, right_channel)\n",
    "plt.title('Right Camera')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(0, right_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af93408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the impulse. The impulse should be the highest value in the signal.\n",
    "# Use the region around the impulse for matrix profile later\n",
    "\n",
    "left_spike = left_channel.argmax()\n",
    "right_spike = right_channel.argmax()\n",
    "\n",
    "left_spike_start = left_spike-10000\n",
    "left_spike_end = left_spike+10000\n",
    "\n",
    "right_spike_start = right_spike-10000\n",
    "right_spike_end = right_spike+10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot around the impulse for the left camera\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times_left, left_channel)\n",
    "plt.plot(times_left[left_spike_start:left_spike_end], left_channel[left_spike_start:left_spike_end], color=\"r\")\n",
    "plt.title('Left Camera')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(0, left_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot around the impulse for the right camera\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times_right, right_channel)\n",
    "plt.plot(times_right[right_spike-10000:right_spike+10000], right_channel[right_spike-10000:right_spike+10000], color=\"r\")\n",
    "\n",
    "plt.title('Right Camera')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(0, right_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf815c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the subarrays for the matrix profile algorithm\n",
    "# The matrix profile algorithm, specifically for conserved pattern detection\n",
    "# To read more about matrix profiles, visit matrixprofile.org\n",
    "\n",
    "m = 10000\n",
    "left_subarray = left_channel[left_spike_start:left_spike_end]\n",
    "right_subarray = right_channel[right_spike_start:right_spike_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffe846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix profile can find patterns in nlogn time, so we use it to quickly find conserved patterns.\n",
    "\n",
    "matrix_profile = stumpy.stump(T_A=left_subarray.astype(np.float64), m=m, T_B=right_subarray.astype(np.float64), ignore_trivial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the matrix profile\n",
    "\n",
    "plt.plot(matrix_profile[:,0])\n",
    "plt.title('Matrix Profile')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Subsequence Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703dc77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of th eleft and right motifs\n",
    "\n",
    "left_motif_index = matrix_profile[:,0].argmin()\n",
    "right_motif_index = matrix_profile[left_motif_index,1] + right_spike_start\n",
    "left_motif_index += left_spike_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot where the conserved motif occurs in the left audio\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times_left, left_channel)\n",
    "plt.plot(times_left[left_motif_index:left_motif_index+m], left_channel[left_motif_index:left_motif_index+m], color=\"red\")\n",
    "plt.title('Left Camera')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(0, left_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86020807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot where the conserved motif occurs in the right audio\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(times_right, right_channel)\n",
    "plt.plot(times_right[right_motif_index:right_motif_index+m], right_channel[right_motif_index:right_motif_index+m], color=\"red\")\n",
    "plt.title('Right Camera')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(0, right_audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119cd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plotted motif should be the same, if not very simliar to, the consecutive cell\n",
    "\n",
    "plt.plot(times_right[right_motif_index:right_motif_index+m], right_channel[right_motif_index:right_motif_index+m])\n",
    "plt.title('Right Camera Most Similar Subsequence')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b64579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plotted motif should be the same, if not very similar to, the previous cell\n",
    "\n",
    "plt.plot(times_left[left_motif_index:left_motif_index+m], left_channel[left_motif_index:left_motif_index+m])\n",
    "plt.title('Left Camera Most Similar Subsequence')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The start and end times for each motif, on the left audio and the right audio\n",
    "\n",
    "print(times_left[left_motif_index])\n",
    "print(times_left[-1])\n",
    "print(times_right[right_motif_index])\n",
    "print(times_right[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b462bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the desired cropped left camera video\n",
    "\n",
    "test = VideoFileClip(\"left.mp4\")\n",
    "test = test.subclip(times_left[left_motif_index],times_left[-1])\n",
    "\n",
    "test.ipython_display(filename=\"left_trimmed.mp4\", width=360)\n",
    "os.rename(\"__temp__.mp4\", \"left_trimmed.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the desired cropped right camera video\n",
    "\n",
    "test = VideoFileClip(\"right.mp4\")\n",
    "test = test.subclip(times_right[right_motif_index],times_right[-1])\n",
    "\n",
    "test.ipython_display(filename=\"right_trimmed.mp4\", width=360)\n",
    "os.rename(\"__temp__.mp4\", \"right_trimmed.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
